{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37364bitsiamesepipenv1dca38cefd8c4466a3050ec6b215d90c",
   "display_name": "Python 3.7.3 64-bit ('Siamese': pipenv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "import glob\n",
    "from Model import model \n",
    "from PIL import Image,ImageOps\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImage(img):\n",
    "    plt.grid(False)\n",
    "    plt.gray()\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img)\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "for i,d in enumerate(glob.glob(\"../..//Dataset/*/\")) : \n",
    "    dataset.append({\n",
    "            \"forged\" : [(np.array(ImageOps.fit(Image.open(im).convert('L'),(1500,750), Image.BILINEAR))/255.0).reshape(1500,750,1) for im in glob.glob(d+\"forged/*\")],\n",
    "            \"genuine\" : [(np.array(ImageOps.fit(Image.open(im).convert('L'),(1500,750), Image.BILINEAR))/255.0).reshape(1500,750,1)  for im in glob.glob(d+\"genuine/*\")]\n",
    "        }) \n",
    "print(len(dataset)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = []\n",
    "labels = []\n",
    "for pt in dataset:    \n",
    "    anchor = pt[\"genuine\"][0] \n",
    "    if(id == 16): print(len(list(zip(pt[\"forged\"],pt[\"genuine\"]))))\n",
    "    for f,g in zip(pt[\"forged\"],pt[\"genuine\"]):\n",
    "        pairs.append([anchor,f])\n",
    "        labels.append(0.0)\n",
    "        pairs.append([anchor,g])\n",
    "        labels.append(1.0)\n",
    "        \n",
    "print(f\"Total Pairs : {len(pairs)}\")  \n",
    "\n",
    "pairs = np.array(pairs)\n",
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(pairs,labels, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_loss(y,Dw): \n",
    "    alpha = 10**(-4)\n",
    "    beta = 0.75\n",
    "    margin = 1\n",
    "    square_pred = K.square(Dw)\n",
    "    margin_square = K.square(K.maximum(margin - Dw, 0)) \n",
    "    return alpha*(1-y) * square_pred + beta * y * margin_square\n",
    "def dist(v):\n",
    "  a,b = v\n",
    "  return np.linalg.norm(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_network(): \n",
    "    input = tf.keras.layers.Input(shape=(1500,750,1))\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(96, (11, 11), activation=\"relu\", input_shape=(1500, 750,1))(input)\n",
    "    x = tf.keras.layers.MaxPooling2D(3, 3)(x)\n",
    "    x = tf.keras.layers.Conv2D(256, (5, 5), activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(3, 3)(x)\n",
    "    x = tf.keras.layers.Dropout(0.3, noise_shape=None, seed=None)(x)\n",
    "    x = tf.keras.layers.Conv2D(384, (3, 3), activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Conv2D(256, (3, 3), activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(3, 3)(x)\n",
    "    x = tf.keras.layers.Dropout(0.3, noise_shape=None, seed=None)(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dropout(0.5, noise_shape=None, seed=None)(x)\n",
    "     \n",
    "    return tf.keras.models.Model(input, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_a = tf.keras.layers.Input((1500,750,1))\n",
    "input_b = tf.keras.layers.Input((1500,750,1))\n",
    "base_network = create_base_network() \n",
    "processed_a = base_network(input_a)\n",
    "processed_b = base_network(input_b)  \n",
    "from keras import backend as K \n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    sum_square = K.sum(K.square(x - y), axis=1, keepdims=True)\n",
    "    return K.sqrt(K.maximum(sum_square, K.epsilon()))\n",
    "\n",
    "def eucl_dist_output_shape(shapes):\n",
    "    shape1, shape2 = shapes\n",
    "    return (shape1[0], 1)\n",
    "\n",
    "distance = tf.keras.layers.Lambda(euclidean_distance,output_shape=eucl_dist_output_shape)([processed_a, processed_b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Model([input_a, input_b], distance)\n",
    "adam = tf.keras.optimizers.Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(loss=contrastive_loss, optimizer=adam,metrics=['accuracy'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit([X_train[:,0], X_train[:,1]], y_train,epochs=10,validation_data=([X_test[:, 0], X_test[:, 1]], y_test))"
   ]
  }
 ]
}